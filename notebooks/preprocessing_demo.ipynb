{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline Demo\n",
    "## Artifice vs Nature - AI Image Detection\n",
    "\n",
    "**Environment:** AMD RX 580 (ROCm 3.5) | PyTorch 1.7.0 | Ubuntu 20.04\n",
    "\n",
    "**Pipeline:** JPEG ‚Üí Resize ‚Üí Augment ‚Üí Normalize ‚Üí Mask ‚Üí DCT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 1: Install PyTorch & torchvision from local .whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/fadhly/comvis/2kripsi/artifice-vs-nature/lib/torch-1.7.0a0-cp38-cp38-linux_x86_64.whl\n",
      "Requirement already satisfied: numpy in /home/fadhly/comvis/2kripsi/artifice-vs-nature/.venv/lib/python3.8/site-packages (from torch==1.7.0a0) (1.24.4)\n",
      "Requirement already satisfied: typing-extensions in /home/fadhly/comvis/2kripsi/artifice-vs-nature/.venv/lib/python3.8/site-packages (from torch==1.7.0a0) (4.13.2)\n",
      "torch is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Processing /home/fadhly/comvis/2kripsi/artifice-vs-nature/lib/torchvision-0.8.0a0+2f40a48-cp38-cp38-linux_x86_64.whl\n",
      "Requirement already satisfied: numpy in /home/fadhly/comvis/2kripsi/artifice-vs-nature/.venv/lib/python3.8/site-packages (from torchvision==0.8.0a0+2f40a48) (1.24.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/fadhly/comvis/2kripsi/artifice-vs-nature/.venv/lib/python3.8/site-packages (from torchvision==0.8.0a0+2f40a48) (10.4.0)\n",
      "Requirement already satisfied: torch in /home/fadhly/comvis/2kripsi/artifice-vs-nature/.venv/lib/python3.8/site-packages (from torchvision==0.8.0a0+2f40a48) (1.7.0a0)\n",
      "Requirement already satisfied: typing-extensions in /home/fadhly/comvis/2kripsi/artifice-vs-nature/.venv/lib/python3.8/site-packages (from torch->torchvision==0.8.0a0+2f40a48) (4.13.2)\n",
      "torchvision is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ PyTorch & torchvision installed successfully\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch 1.7.0 and torchvision 0.8.1 for ROCm 3.5\n",
    "%pip install ../lib/torch-1.7.0a0-cp38-cp38-linux_x86_64.whl\n",
    "%pip install ../lib/torchvision-0.8.0a0+2f40a48-cp38-cp38-linux_x86_64.whl\n",
    "\n",
    "print(\"‚úÖ PyTorch & torchvision installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2: Import all required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Device: cuda\n",
      "üéÆ GPU: Ellesmere [Radeon RX 470/480/570/570X/580/580X/590]\n",
      "üíæ VRAM: 8.59 GB\n",
      "\n",
      "‚úÖ All modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import yaml\n",
    "\n",
    "# Import preprocessing modules\n",
    "from src.preprocessing import (\n",
    "    apply_jpeg,\n",
    "    resize_to_224,\n",
    "    apply_augment,\n",
    "    normalize_image,\n",
    "    apply_mask,\n",
    "    extract_dct_features,\n",
    "    preprocess_full\n",
    ")\n",
    "\n",
    "# Import visualization\n",
    "from src.utils import plot_preprocessing_pipeline\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Enable matplotlib inline\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"\\n‚úÖ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 3: Load configuration from YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Preprocessing Configuration:\n",
      "augmentation:\n",
      "  brightness_range:\n",
      "  - -0.2\n",
      "  - 0.2\n",
      "  contrast_range:\n",
      "  - -0.2\n",
      "  - 0.2\n",
      "  horizontal_flip_prob: 0.5\n",
      "dct:\n",
      "  block_size: 8\n",
      "  top_k: 1024\n",
      "jpeg:\n",
      "  prob: 0.7\n",
      "  quality_range:\n",
      "  - 30\n",
      "  - 90\n",
      "mask:\n",
      "  ratio: 0.2\n",
      "normalization:\n",
      "  mean:\n",
      "  - 0.485\n",
      "  - 0.456\n",
      "  - 0.406\n",
      "  std:\n",
      "  - 0.229\n",
      "  - 0.224\n",
      "  - 0.225\n",
      "\n",
      "‚úÖ Configuration loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessing config\n",
    "with open('../configs/preprocessing.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìã Preprocessing Configuration:\")\n",
    "print(yaml.dump(config, default_flow_style=False))\n",
    "\n",
    "print(\"‚úÖ Configuration loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 4: Load sample image\n",
    "\n",
    "**Note:** Place a sample image in `data/raw/imaginet/subset/anime/` or update the path below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and use an available image from the dataset\n",
    "import glob\n",
    "\n",
    "# Try to find any image in data directory\n",
    "img_paths = (\n",
    "    glob.glob(\"../data/processed/**/*.jpg\", recursive=True) +\n",
    "    glob.glob(\"../data/processed/**/*.png\", recursive=True) +\n",
    "    glob.glob(\"../data/raw/**/*.jpg\", recursive=True) +\n",
    "    glob.glob(\"../data/raw/**/*.png\", recursive=True)\n",
    ")\n",
    "\n",
    "if img_paths:\n",
    "    img_path = img_paths[0]\n",
    "    print(f\"üìÅ Using: {img_path}\")\n",
    "else:\n",
    "    # Fallback: use sample path (user should place an image here)\n",
    "    img_path = \"../data/raw/imaginet/subset/anime/sample.jpg\"\n",
    "    print(f\"‚ö†Ô∏è  Default path: {img_path}\")\n",
    "    print(\"   Please place a sample image if not found\")\n",
    "\n",
    "try:\n",
    "    img = Image.open(img_path)\n",
    "    print(f\"‚úÖ Image loaded successfully\")\n",
    "    print(f\"üìê Original size: {img.size}\")\n",
    "    print(f\"üé® Mode: {img.mode}\")\n",
    "    \n",
    "    # Display original image\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Original Image ({img.size[0]}√ó{img.size[1]})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Image not found: {img_path}\")\n",
    "    print(\"\\nüí° Please place a sample image in data directory\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading image: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 5: Run full preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full preprocessing pipeline\n",
    "result = preprocess_full(img_path, config)\n",
    "\n",
    "print(\"üîÑ Preprocessing Pipeline Completed\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract results\n",
    "img_masked = result['img_masked']\n",
    "dct_feat = result['dct_feat']\n",
    "intermediates = result['intermediates']\n",
    "\n",
    "print(f\"\\nüìä Output Shapes:\")\n",
    "print(f\"  - Masked Image: {img_masked.shape}\")\n",
    "print(f\"  - DCT Features: {dct_feat.shape}\")\n",
    "\n",
    "print(f\"\\nüîç Intermediate Results:\")\n",
    "print(f\"  - Original size: {intermediates['original_size']}\")\n",
    "print(f\"  - JPEG quality: {intermediates['jpeg_quality']}\")\n",
    "print(f\"  - DCT coefficients: {len(intermediates['dct_values'])}\")\n",
    "\n",
    "print(f\"\\nüìà Tensor Statistics:\")\n",
    "print(f\"  - Masked image mean: {img_masked.mean():.4f}\")\n",
    "print(f\"  - Masked image std: {img_masked.std():.4f}\")\n",
    "print(f\"  - DCT features mean: {dct_feat.mean():.4f}\")\n",
    "print(f\"  - DCT features std: {dct_feat.std():.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline execution successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 6: Visualize preprocessing stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 4-panel preprocessing pipeline\n",
    "fig = plot_preprocessing_pipeline(intermediates, figsize=(14, 10))\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 7: Display detailed shapes and verify output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Final Output Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£  Masked Image Tensor:\")\n",
    "print(f\"   - Shape: {img_masked.shape}\")\n",
    "print(f\"   - Dtype: {img_masked.dtype}\")\n",
    "print(f\"   - Device: {img_masked.device}\")\n",
    "print(f\"   - Min/Max: {img_masked.min():.4f} / {img_masked.max():.4f}\")\n",
    "print(f\"   - Memory: {img_masked.element_size() * img_masked.nelement() / 1024:.2f} KB\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£  DCT Feature Vector:\")\n",
    "print(f\"   - Shape: {dct_feat.shape}\")\n",
    "print(f\"   - Dtype: {dct_feat.dtype}\")\n",
    "print(f\"   - Device: {dct_feat.device}\")\n",
    "print(f\"   - Min/Max: {dct_feat.min():.4f} / {dct_feat.max():.4f}\")\n",
    "print(f\"   - Memory: {dct_feat.element_size() * dct_feat.nelement() / 1024:.2f} KB\")\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£  Intermediate Stages Available:\")\n",
    "for key in intermediates.keys():\n",
    "    print(f\"   - {key}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ All preprocessing steps verified successfully!\")\n",
    "print(\"üöÄ Ready for model training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "1. **Batch Processing**: Process entire dataset using `preprocess_full()`\n",
    "2. **Save Preprocessed Data**: Store in `data/processed/imaginet/subset/`\n",
    "3. **Model Training**: Use `img_masked` as model input\n",
    "4. **Feature Analysis**: Analyze DCT features for AI vs real patterns\n",
    "\n",
    "---\n",
    "**Project:** Artifice vs Nature | **Device:** AMD RX 580 (ROCm 3.5) | **Framework:** PyTorch 1.7.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
